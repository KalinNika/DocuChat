import os
from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_ollama.embeddings import OllamaEmbeddings

def load_and_split_pdfs(pdf_paths):
    all_chunks = []
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)

    for path in pdf_paths:
        if not os.path.exists(path):
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
            continue

        loader = PyMuPDFLoader(path)
        documents = loader.load()
        chunks = splitter.split_documents(documents)
        print(f"‚úÖ {len(chunks)} —á–∞–Ω–∫–æ–≤ –∏–∑ {path}")
        all_chunks.extend(chunks)

    return all_chunks

def build_vectorstore(chunks, persist_path):
    embeddings = ChatOllama(model="mistral", base_url="http://host.docker.internal:8080")
    vectorstore = FAISS.from_documents(chunks, embeddings)
    vectorstore.save_local(persist_path)
    print(f"‚úÖ –í–µ–∫—Ç–æ—Ä–Ω–∞—è –±–∞–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {persist_path}")

if __name__ == "__main__":
    pdf_files = ["data/file1.pdf"]
    persist_dir = "vectorstore-chekhov/"  # üëà –Ω–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è

    chunks = load_and_split_pdfs(pdf_files)
    if chunks:
        build_vectorstore(chunks, persist_dir)
    else:
        print("‚ùå –ß–∞–Ω–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã ‚Äî –±–∞–∑–∞ –Ω–µ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞–Ω–∞.")
